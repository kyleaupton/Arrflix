// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: download_jobs.sql

package dbgen

import (
	"context"
	"time"

	"github.com/jackc/pgx/v5/pgtype"
)

const cancelDownloadJob = `-- name: CancelDownloadJob :one
UPDATE download_job
SET status = 'cancelled',
    updated_at = now()
WHERE id = $1
  AND status NOT IN ('completed', 'failed', 'cancelled')
RETURNING id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at
`

func (q *Queries) CancelDownloadJob(ctx context.Context, id pgtype.UUID) (DownloadJob, error) {
	row := q.db.QueryRow(ctx, cancelDownloadJob, id)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.Status,
		&i.Protocol,
		&i.IndexerID,
		&i.Guid,
		&i.CandidateTitle,
		&i.CandidateLink,
		&i.MediaType,
		&i.MediaItemID,
		&i.EpisodeID,
		&i.LibraryID,
		&i.NameTemplateID,
		&i.DownloaderID,
		&i.DownloaderExternalID,
		&i.DownloaderStatus,
		&i.Progress,
		&i.SavePath,
		&i.ContentPath,
		&i.AttemptCount,
		&i.NextRunAt,
		&i.LastError,
		&i.ErrorCategory,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const claimRunnableDownloadJobs = `-- name: ClaimRunnableDownloadJobs :many
WITH cte AS (
  SELECT id
  FROM download_job
  WHERE status IN ('created', 'enqueued', 'downloading')
    AND next_run_at <= now()
  ORDER BY next_run_at ASC
  FOR UPDATE SKIP LOCKED
  LIMIT $1
)
UPDATE download_job j
SET updated_at = now()
FROM cte
WHERE j.id = cte.id
RETURNING j.id, j.status, j.protocol, j.indexer_id, j.guid, j.candidate_title, j.candidate_link, j.media_type, j.media_item_id, j.episode_id, j.library_id, j.name_template_id, j.downloader_id, j.downloader_external_id, j.downloader_status, j.progress, j.save_path, j.content_path, j.attempt_count, j.next_run_at, j.last_error, j.error_category, j.created_at, j.updated_at
`

// Claims jobs that are ready to be processed (created, enqueued, or downloading)
// Uses FOR UPDATE SKIP LOCKED to prevent duplicate processing
func (q *Queries) ClaimRunnableDownloadJobs(ctx context.Context, limit int32) ([]DownloadJob, error) {
	rows, err := q.db.Query(ctx, claimRunnableDownloadJobs, limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []DownloadJob
	for rows.Next() {
		var i DownloadJob
		if err := rows.Scan(
			&i.ID,
			&i.Status,
			&i.Protocol,
			&i.IndexerID,
			&i.Guid,
			&i.CandidateTitle,
			&i.CandidateLink,
			&i.MediaType,
			&i.MediaItemID,
			&i.EpisodeID,
			&i.LibraryID,
			&i.NameTemplateID,
			&i.DownloaderID,
			&i.DownloaderExternalID,
			&i.DownloaderStatus,
			&i.Progress,
			&i.SavePath,
			&i.ContentPath,
			&i.AttemptCount,
			&i.NextRunAt,
			&i.LastError,
			&i.ErrorCategory,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const createDownloadJob = `-- name: CreateDownloadJob :one

INSERT INTO download_job (
  status,
  protocol,
  media_type,
  media_item_id,
  episode_id,
  indexer_id,
  guid,
  candidate_title,
  candidate_link,
  downloader_id,
  library_id,
  name_template_id
)
VALUES (
  'created',
  $1,
  $2,
  $3,
  $4,
  $5,
  $6,
  $7,
  $8,
  $9,
  $10,
  $11
)
ON CONFLICT (indexer_id, guid) DO UPDATE
SET updated_at = now()
RETURNING id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at
`

type CreateDownloadJobParams struct {
	Protocol       string      `json:"protocol"`
	MediaType      string      `json:"media_type"`
	MediaItemID    pgtype.UUID `json:"media_item_id"`
	EpisodeID      pgtype.UUID `json:"episode_id"`
	IndexerID      int64       `json:"indexer_id"`
	Guid           string      `json:"guid"`
	CandidateTitle string      `json:"candidate_title"`
	CandidateLink  string      `json:"candidate_link"`
	DownloaderID   pgtype.UUID `json:"downloader_id"`
	LibraryID      pgtype.UUID `json:"library_id"`
	NameTemplateID pgtype.UUID `json:"name_template_id"`
}

// Download jobs (refactored: 6 states, no import states)
func (q *Queries) CreateDownloadJob(ctx context.Context, arg CreateDownloadJobParams) (DownloadJob, error) {
	row := q.db.QueryRow(ctx, createDownloadJob,
		arg.Protocol,
		arg.MediaType,
		arg.MediaItemID,
		arg.EpisodeID,
		arg.IndexerID,
		arg.Guid,
		arg.CandidateTitle,
		arg.CandidateLink,
		arg.DownloaderID,
		arg.LibraryID,
		arg.NameTemplateID,
	)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.Status,
		&i.Protocol,
		&i.IndexerID,
		&i.Guid,
		&i.CandidateTitle,
		&i.CandidateLink,
		&i.MediaType,
		&i.MediaItemID,
		&i.EpisodeID,
		&i.LibraryID,
		&i.NameTemplateID,
		&i.DownloaderID,
		&i.DownloaderExternalID,
		&i.DownloaderStatus,
		&i.Progress,
		&i.SavePath,
		&i.ContentPath,
		&i.AttemptCount,
		&i.NextRunAt,
		&i.LastError,
		&i.ErrorCategory,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getDownloadJob = `-- name: GetDownloadJob :one
SELECT id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at FROM download_job
WHERE id = $1
`

func (q *Queries) GetDownloadJob(ctx context.Context, id pgtype.UUID) (DownloadJob, error) {
	row := q.db.QueryRow(ctx, getDownloadJob, id)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.Status,
		&i.Protocol,
		&i.IndexerID,
		&i.Guid,
		&i.CandidateTitle,
		&i.CandidateLink,
		&i.MediaType,
		&i.MediaItemID,
		&i.EpisodeID,
		&i.LibraryID,
		&i.NameTemplateID,
		&i.DownloaderID,
		&i.DownloaderExternalID,
		&i.DownloaderStatus,
		&i.Progress,
		&i.SavePath,
		&i.ContentPath,
		&i.AttemptCount,
		&i.NextRunAt,
		&i.LastError,
		&i.ErrorCategory,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getDownloadJobByCandidate = `-- name: GetDownloadJobByCandidate :one
SELECT id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at FROM download_job
WHERE indexer_id = $1 AND guid = $2
`

type GetDownloadJobByCandidateParams struct {
	IndexerID int64  `json:"indexer_id"`
	Guid      string `json:"guid"`
}

func (q *Queries) GetDownloadJobByCandidate(ctx context.Context, arg GetDownloadJobByCandidateParams) (DownloadJob, error) {
	row := q.db.QueryRow(ctx, getDownloadJobByCandidate, arg.IndexerID, arg.Guid)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.Status,
		&i.Protocol,
		&i.IndexerID,
		&i.Guid,
		&i.CandidateTitle,
		&i.CandidateLink,
		&i.MediaType,
		&i.MediaItemID,
		&i.EpisodeID,
		&i.LibraryID,
		&i.NameTemplateID,
		&i.DownloaderID,
		&i.DownloaderExternalID,
		&i.DownloaderStatus,
		&i.Progress,
		&i.SavePath,
		&i.ContentPath,
		&i.AttemptCount,
		&i.NextRunAt,
		&i.LastError,
		&i.ErrorCategory,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const getDownloadJobTimeline = `-- name: GetDownloadJobTimeline :many
SELECT
  'download' AS source,
  e.id,
  e.event_type,
  e.old_status,
  e.new_status,
  e.message,
  e.metadata,
  e.created_at,
  NULL::uuid AS import_task_id
FROM download_job_event e
WHERE e.download_job_id = $1

UNION ALL

SELECT
  'import' AS source,
  ie.id,
  ie.event_type,
  ie.old_status,
  ie.new_status,
  ie.message,
  ie.metadata,
  ie.created_at,
  ie.import_task_id
FROM import_task_event ie
JOIN import_task it ON it.id = ie.import_task_id
WHERE it.download_job_id = $1

ORDER BY created_at ASC
`

type GetDownloadJobTimelineRow struct {
	Source       string      `json:"source"`
	ID           pgtype.UUID `json:"id"`
	EventType    string      `json:"event_type"`
	OldStatus    *string     `json:"old_status"`
	NewStatus    *string     `json:"new_status"`
	Message      *string     `json:"message"`
	Metadata     []byte      `json:"metadata"`
	CreatedAt    time.Time   `json:"created_at"`
	ImportTaskID pgtype.UUID `json:"import_task_id"`
}

// Combined event log for a download job (download events + related import events)
func (q *Queries) GetDownloadJobTimeline(ctx context.Context, downloadJobID pgtype.UUID) ([]GetDownloadJobTimelineRow, error) {
	rows, err := q.db.Query(ctx, getDownloadJobTimeline, downloadJobID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []GetDownloadJobTimelineRow
	for rows.Next() {
		var i GetDownloadJobTimelineRow
		if err := rows.Scan(
			&i.Source,
			&i.ID,
			&i.EventType,
			&i.OldStatus,
			&i.NewStatus,
			&i.Message,
			&i.Metadata,
			&i.CreatedAt,
			&i.ImportTaskID,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const getDownloadJobWithImportSummary = `-- name: GetDownloadJobWithImportSummary :one
SELECT
  dj.id, dj.status, dj.protocol, dj.indexer_id, dj.guid, dj.candidate_title, dj.candidate_link, dj.media_type, dj.media_item_id, dj.episode_id, dj.library_id, dj.name_template_id, dj.downloader_id, dj.downloader_external_id, dj.downloader_status, dj.progress, dj.save_path, dj.content_path, dj.attempt_count, dj.next_run_at, dj.last_error, dj.error_category, dj.created_at, dj.updated_at,
  COUNT(it.id)::int AS total_import_tasks,
  COUNT(it.id) FILTER (WHERE it.status = 'pending')::int AS pending_imports,
  COUNT(it.id) FILTER (WHERE it.status = 'in_progress')::int AS active_imports,
  COUNT(it.id) FILTER (WHERE it.status = 'completed')::int AS completed_imports,
  COUNT(it.id) FILTER (WHERE it.status = 'failed')::int AS failed_imports,
  COUNT(it.id) FILTER (WHERE it.status = 'cancelled')::int AS cancelled_imports,
  CASE
    WHEN dj.status != 'completed' THEN 'download_pending'
    WHEN COUNT(it.id) = 0 THEN 'awaiting_import'
    WHEN COUNT(it.id) FILTER (WHERE it.status IN ('pending', 'in_progress')) > 0 THEN 'importing'
    WHEN COUNT(it.id) FILTER (WHERE it.status = 'failed') > 0
         AND COUNT(it.id) FILTER (WHERE it.status = 'completed') > 0 THEN 'partial_failure'
    WHEN COUNT(it.id) FILTER (WHERE it.status = 'failed') = COUNT(it.id) THEN 'import_failed'
    WHEN COUNT(it.id) = COUNT(it.id) FILTER (WHERE it.status = 'completed') THEN 'fully_imported'
    ELSE 'unknown'
  END AS import_status
FROM download_job dj
LEFT JOIN import_task it ON it.download_job_id = dj.id
  AND it.previous_task_id IS NULL  -- Only count "root" tasks, not reimports
WHERE dj.id = $1
GROUP BY dj.id
`

type GetDownloadJobWithImportSummaryRow struct {
	ID                   pgtype.UUID `json:"id"`
	Status               string      `json:"status"`
	Protocol             string      `json:"protocol"`
	IndexerID            int64       `json:"indexer_id"`
	Guid                 string      `json:"guid"`
	CandidateTitle       string      `json:"candidate_title"`
	CandidateLink        string      `json:"candidate_link"`
	MediaType            string      `json:"media_type"`
	MediaItemID          pgtype.UUID `json:"media_item_id"`
	EpisodeID            pgtype.UUID `json:"episode_id"`
	LibraryID            pgtype.UUID `json:"library_id"`
	NameTemplateID       pgtype.UUID `json:"name_template_id"`
	DownloaderID         pgtype.UUID `json:"downloader_id"`
	DownloaderExternalID *string     `json:"downloader_external_id"`
	DownloaderStatus     *string     `json:"downloader_status"`
	Progress             *float64    `json:"progress"`
	SavePath             *string     `json:"save_path"`
	ContentPath          *string     `json:"content_path"`
	AttemptCount         int32       `json:"attempt_count"`
	NextRunAt            time.Time   `json:"next_run_at"`
	LastError            *string     `json:"last_error"`
	ErrorCategory        *string     `json:"error_category"`
	CreatedAt            time.Time   `json:"created_at"`
	UpdatedAt            time.Time   `json:"updated_at"`
	TotalImportTasks     int32       `json:"total_import_tasks"`
	PendingImports       int32       `json:"pending_imports"`
	ActiveImports        int32       `json:"active_imports"`
	CompletedImports     int32       `json:"completed_imports"`
	FailedImports        int32       `json:"failed_imports"`
	CancelledImports     int32       `json:"cancelled_imports"`
	ImportStatus         string      `json:"import_status"`
}

// Returns download job with computed import status summary
func (q *Queries) GetDownloadJobWithImportSummary(ctx context.Context, id pgtype.UUID) (GetDownloadJobWithImportSummaryRow, error) {
	row := q.db.QueryRow(ctx, getDownloadJobWithImportSummary, id)
	var i GetDownloadJobWithImportSummaryRow
	err := row.Scan(
		&i.ID,
		&i.Status,
		&i.Protocol,
		&i.IndexerID,
		&i.Guid,
		&i.CandidateTitle,
		&i.CandidateLink,
		&i.MediaType,
		&i.MediaItemID,
		&i.EpisodeID,
		&i.LibraryID,
		&i.NameTemplateID,
		&i.DownloaderID,
		&i.DownloaderExternalID,
		&i.DownloaderStatus,
		&i.Progress,
		&i.SavePath,
		&i.ContentPath,
		&i.AttemptCount,
		&i.NextRunAt,
		&i.LastError,
		&i.ErrorCategory,
		&i.CreatedAt,
		&i.UpdatedAt,
		&i.TotalImportTasks,
		&i.PendingImports,
		&i.ActiveImports,
		&i.CompletedImports,
		&i.FailedImports,
		&i.CancelledImports,
		&i.ImportStatus,
	)
	return i, err
}

const listDownloadJobs = `-- name: ListDownloadJobs :many
SELECT id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at FROM download_job
ORDER BY created_at DESC
`

func (q *Queries) ListDownloadJobs(ctx context.Context) ([]DownloadJob, error) {
	rows, err := q.db.Query(ctx, listDownloadJobs)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []DownloadJob
	for rows.Next() {
		var i DownloadJob
		if err := rows.Scan(
			&i.ID,
			&i.Status,
			&i.Protocol,
			&i.IndexerID,
			&i.Guid,
			&i.CandidateTitle,
			&i.CandidateLink,
			&i.MediaType,
			&i.MediaItemID,
			&i.EpisodeID,
			&i.LibraryID,
			&i.NameTemplateID,
			&i.DownloaderID,
			&i.DownloaderExternalID,
			&i.DownloaderStatus,
			&i.Progress,
			&i.SavePath,
			&i.ContentPath,
			&i.AttemptCount,
			&i.NextRunAt,
			&i.LastError,
			&i.ErrorCategory,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listDownloadJobsByMediaItem = `-- name: ListDownloadJobsByMediaItem :many
SELECT id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at FROM download_job
WHERE media_item_id = $1
ORDER BY created_at DESC
`

func (q *Queries) ListDownloadJobsByMediaItem(ctx context.Context, mediaItemID pgtype.UUID) ([]DownloadJob, error) {
	rows, err := q.db.Query(ctx, listDownloadJobsByMediaItem, mediaItemID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []DownloadJob
	for rows.Next() {
		var i DownloadJob
		if err := rows.Scan(
			&i.ID,
			&i.Status,
			&i.Protocol,
			&i.IndexerID,
			&i.Guid,
			&i.CandidateTitle,
			&i.CandidateLink,
			&i.MediaType,
			&i.MediaItemID,
			&i.EpisodeID,
			&i.LibraryID,
			&i.NameTemplateID,
			&i.DownloaderID,
			&i.DownloaderExternalID,
			&i.DownloaderStatus,
			&i.Progress,
			&i.SavePath,
			&i.ContentPath,
			&i.AttemptCount,
			&i.NextRunAt,
			&i.LastError,
			&i.ErrorCategory,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listDownloadJobsByTmdbMovieID = `-- name: ListDownloadJobsByTmdbMovieID :many
SELECT j.id, j.status, j.protocol, j.indexer_id, j.guid, j.candidate_title, j.candidate_link, j.media_type, j.media_item_id, j.episode_id, j.library_id, j.name_template_id, j.downloader_id, j.downloader_external_id, j.downloader_status, j.progress, j.save_path, j.content_path, j.attempt_count, j.next_run_at, j.last_error, j.error_category, j.created_at, j.updated_at
FROM download_job j
JOIN media_item mi ON mi.id = j.media_item_id
WHERE mi.type = 'movie' AND mi.tmdb_id = $1
ORDER BY j.created_at DESC
`

func (q *Queries) ListDownloadJobsByTmdbMovieID(ctx context.Context, tmdbID *int64) ([]DownloadJob, error) {
	rows, err := q.db.Query(ctx, listDownloadJobsByTmdbMovieID, tmdbID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []DownloadJob
	for rows.Next() {
		var i DownloadJob
		if err := rows.Scan(
			&i.ID,
			&i.Status,
			&i.Protocol,
			&i.IndexerID,
			&i.Guid,
			&i.CandidateTitle,
			&i.CandidateLink,
			&i.MediaType,
			&i.MediaItemID,
			&i.EpisodeID,
			&i.LibraryID,
			&i.NameTemplateID,
			&i.DownloaderID,
			&i.DownloaderExternalID,
			&i.DownloaderStatus,
			&i.Progress,
			&i.SavePath,
			&i.ContentPath,
			&i.AttemptCount,
			&i.NextRunAt,
			&i.LastError,
			&i.ErrorCategory,
			&i.CreatedAt,
			&i.UpdatedAt,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const listDownloadJobsByTmdbSeriesID = `-- name: ListDownloadJobsByTmdbSeriesID :many
SELECT j.id, j.status, j.protocol, j.indexer_id, j.guid, j.candidate_title, j.candidate_link, j.media_type, j.media_item_id, j.episode_id, j.library_id, j.name_template_id, j.downloader_id, j.downloader_external_id, j.downloader_status, j.progress, j.save_path, j.content_path, j.attempt_count, j.next_run_at, j.last_error, j.error_category, j.created_at, j.updated_at,
       ms.season_number,
       me.episode_number
FROM download_job j
JOIN media_item mi ON mi.id = j.media_item_id
LEFT JOIN media_episode me ON me.id = j.episode_id
LEFT JOIN media_season ms ON ms.id = me.season_id
WHERE mi.type = 'series' AND mi.tmdb_id = $1
ORDER BY j.created_at DESC
`

type ListDownloadJobsByTmdbSeriesIDRow struct {
	ID                   pgtype.UUID `json:"id"`
	Status               string      `json:"status"`
	Protocol             string      `json:"protocol"`
	IndexerID            int64       `json:"indexer_id"`
	Guid                 string      `json:"guid"`
	CandidateTitle       string      `json:"candidate_title"`
	CandidateLink        string      `json:"candidate_link"`
	MediaType            string      `json:"media_type"`
	MediaItemID          pgtype.UUID `json:"media_item_id"`
	EpisodeID            pgtype.UUID `json:"episode_id"`
	LibraryID            pgtype.UUID `json:"library_id"`
	NameTemplateID       pgtype.UUID `json:"name_template_id"`
	DownloaderID         pgtype.UUID `json:"downloader_id"`
	DownloaderExternalID *string     `json:"downloader_external_id"`
	DownloaderStatus     *string     `json:"downloader_status"`
	Progress             *float64    `json:"progress"`
	SavePath             *string     `json:"save_path"`
	ContentPath          *string     `json:"content_path"`
	AttemptCount         int32       `json:"attempt_count"`
	NextRunAt            time.Time   `json:"next_run_at"`
	LastError            *string     `json:"last_error"`
	ErrorCategory        *string     `json:"error_category"`
	CreatedAt            time.Time   `json:"created_at"`
	UpdatedAt            time.Time   `json:"updated_at"`
	SeasonNumber         *int32      `json:"season_number"`
	EpisodeNumber        *int32      `json:"episode_number"`
}

func (q *Queries) ListDownloadJobsByTmdbSeriesID(ctx context.Context, tmdbID *int64) ([]ListDownloadJobsByTmdbSeriesIDRow, error) {
	rows, err := q.db.Query(ctx, listDownloadJobsByTmdbSeriesID, tmdbID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []ListDownloadJobsByTmdbSeriesIDRow
	for rows.Next() {
		var i ListDownloadJobsByTmdbSeriesIDRow
		if err := rows.Scan(
			&i.ID,
			&i.Status,
			&i.Protocol,
			&i.IndexerID,
			&i.Guid,
			&i.CandidateTitle,
			&i.CandidateLink,
			&i.MediaType,
			&i.MediaItemID,
			&i.EpisodeID,
			&i.LibraryID,
			&i.NameTemplateID,
			&i.DownloaderID,
			&i.DownloaderExternalID,
			&i.DownloaderStatus,
			&i.Progress,
			&i.SavePath,
			&i.ContentPath,
			&i.AttemptCount,
			&i.NextRunAt,
			&i.LastError,
			&i.ErrorCategory,
			&i.CreatedAt,
			&i.UpdatedAt,
			&i.SeasonNumber,
			&i.EpisodeNumber,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const markDownloadJobFailed = `-- name: MarkDownloadJobFailed :one
UPDATE download_job
SET status = 'failed',
    last_error = $1,
    error_category = $2,
    updated_at = now()
WHERE id = $3
RETURNING id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at
`

type MarkDownloadJobFailedParams struct {
	LastError     *string     `json:"last_error"`
	ErrorCategory *string     `json:"error_category"`
	ID            pgtype.UUID `json:"id"`
}

func (q *Queries) MarkDownloadJobFailed(ctx context.Context, arg MarkDownloadJobFailedParams) (DownloadJob, error) {
	row := q.db.QueryRow(ctx, markDownloadJobFailed, arg.LastError, arg.ErrorCategory, arg.ID)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.Status,
		&i.Protocol,
		&i.IndexerID,
		&i.Guid,
		&i.CandidateTitle,
		&i.CandidateLink,
		&i.MediaType,
		&i.MediaItemID,
		&i.EpisodeID,
		&i.LibraryID,
		&i.NameTemplateID,
		&i.DownloaderID,
		&i.DownloaderExternalID,
		&i.DownloaderStatus,
		&i.Progress,
		&i.SavePath,
		&i.ContentPath,
		&i.AttemptCount,
		&i.NextRunAt,
		&i.LastError,
		&i.ErrorCategory,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const scheduleDownloadJobRetry = `-- name: ScheduleDownloadJobRetry :one
UPDATE download_job
SET attempt_count = attempt_count + 1,
    last_error = $1,
    error_category = $2,
    next_run_at = $3,
    updated_at = now()
WHERE id = $4
RETURNING id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at
`

type ScheduleDownloadJobRetryParams struct {
	LastError     *string     `json:"last_error"`
	ErrorCategory *string     `json:"error_category"`
	NextRunAt     time.Time   `json:"next_run_at"`
	ID            pgtype.UUID `json:"id"`
}

func (q *Queries) ScheduleDownloadJobRetry(ctx context.Context, arg ScheduleDownloadJobRetryParams) (DownloadJob, error) {
	row := q.db.QueryRow(ctx, scheduleDownloadJobRetry,
		arg.LastError,
		arg.ErrorCategory,
		arg.NextRunAt,
		arg.ID,
	)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.Status,
		&i.Protocol,
		&i.IndexerID,
		&i.Guid,
		&i.CandidateTitle,
		&i.CandidateLink,
		&i.MediaType,
		&i.MediaItemID,
		&i.EpisodeID,
		&i.LibraryID,
		&i.NameTemplateID,
		&i.DownloaderID,
		&i.DownloaderExternalID,
		&i.DownloaderStatus,
		&i.Progress,
		&i.SavePath,
		&i.ContentPath,
		&i.AttemptCount,
		&i.NextRunAt,
		&i.LastError,
		&i.ErrorCategory,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const setDownloadJobCompleted = `-- name: SetDownloadJobCompleted :one
UPDATE download_job
SET status = 'completed',
    save_path = $1,
    content_path = $2,
    updated_at = now()
WHERE id = $3
RETURNING id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at
`

type SetDownloadJobCompletedParams struct {
	SavePath    *string     `json:"save_path"`
	ContentPath *string     `json:"content_path"`
	ID          pgtype.UUID `json:"id"`
}

func (q *Queries) SetDownloadJobCompleted(ctx context.Context, arg SetDownloadJobCompletedParams) (DownloadJob, error) {
	row := q.db.QueryRow(ctx, setDownloadJobCompleted, arg.SavePath, arg.ContentPath, arg.ID)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.Status,
		&i.Protocol,
		&i.IndexerID,
		&i.Guid,
		&i.CandidateTitle,
		&i.CandidateLink,
		&i.MediaType,
		&i.MediaItemID,
		&i.EpisodeID,
		&i.LibraryID,
		&i.NameTemplateID,
		&i.DownloaderID,
		&i.DownloaderExternalID,
		&i.DownloaderStatus,
		&i.Progress,
		&i.SavePath,
		&i.ContentPath,
		&i.AttemptCount,
		&i.NextRunAt,
		&i.LastError,
		&i.ErrorCategory,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const setDownloadJobDownloadSnapshot = `-- name: SetDownloadJobDownloadSnapshot :one
UPDATE download_job
SET status = $1,
    downloader_status = $2,
    progress = $3,
    save_path = $4,
    content_path = $5,
    updated_at = now()
WHERE id = $6
RETURNING id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at
`

type SetDownloadJobDownloadSnapshotParams struct {
	Status           string      `json:"status"`
	DownloaderStatus *string     `json:"downloader_status"`
	Progress         *float64    `json:"progress"`
	SavePath         *string     `json:"save_path"`
	ContentPath      *string     `json:"content_path"`
	ID               pgtype.UUID `json:"id"`
}

func (q *Queries) SetDownloadJobDownloadSnapshot(ctx context.Context, arg SetDownloadJobDownloadSnapshotParams) (DownloadJob, error) {
	row := q.db.QueryRow(ctx, setDownloadJobDownloadSnapshot,
		arg.Status,
		arg.DownloaderStatus,
		arg.Progress,
		arg.SavePath,
		arg.ContentPath,
		arg.ID,
	)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.Status,
		&i.Protocol,
		&i.IndexerID,
		&i.Guid,
		&i.CandidateTitle,
		&i.CandidateLink,
		&i.MediaType,
		&i.MediaItemID,
		&i.EpisodeID,
		&i.LibraryID,
		&i.NameTemplateID,
		&i.DownloaderID,
		&i.DownloaderExternalID,
		&i.DownloaderStatus,
		&i.Progress,
		&i.SavePath,
		&i.ContentPath,
		&i.AttemptCount,
		&i.NextRunAt,
		&i.LastError,
		&i.ErrorCategory,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}

const setDownloadJobEnqueued = `-- name: SetDownloadJobEnqueued :one
UPDATE download_job
SET status = 'enqueued',
    downloader_external_id = $1,
    attempt_count = attempt_count + 1,
    updated_at = now()
WHERE id = $2
RETURNING id, status, protocol, indexer_id, guid, candidate_title, candidate_link, media_type, media_item_id, episode_id, library_id, name_template_id, downloader_id, downloader_external_id, downloader_status, progress, save_path, content_path, attempt_count, next_run_at, last_error, error_category, created_at, updated_at
`

type SetDownloadJobEnqueuedParams struct {
	DownloaderExternalID *string     `json:"downloader_external_id"`
	ID                   pgtype.UUID `json:"id"`
}

func (q *Queries) SetDownloadJobEnqueued(ctx context.Context, arg SetDownloadJobEnqueuedParams) (DownloadJob, error) {
	row := q.db.QueryRow(ctx, setDownloadJobEnqueued, arg.DownloaderExternalID, arg.ID)
	var i DownloadJob
	err := row.Scan(
		&i.ID,
		&i.Status,
		&i.Protocol,
		&i.IndexerID,
		&i.Guid,
		&i.CandidateTitle,
		&i.CandidateLink,
		&i.MediaType,
		&i.MediaItemID,
		&i.EpisodeID,
		&i.LibraryID,
		&i.NameTemplateID,
		&i.DownloaderID,
		&i.DownloaderExternalID,
		&i.DownloaderStatus,
		&i.Progress,
		&i.SavePath,
		&i.ContentPath,
		&i.AttemptCount,
		&i.NextRunAt,
		&i.LastError,
		&i.ErrorCategory,
		&i.CreatedAt,
		&i.UpdatedAt,
	)
	return i, err
}
